{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Notebook\n",
    "Importación de librerías\n"
   ],
   "id": "f78b65bf34750fdb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de ficheros de datos en formato csv"
   ],
   "id": "54a8d9abe85f8ed1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:45.613555700Z",
     "start_time": "2024-03-31T17:53:44.657770700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m wind_ava\u001B[38;5;241m=\u001B[39m\u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_ava.csv.gz\u001B[39m\u001B[38;5;124m'\u001B[39m, compression \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m wind_comp\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_comp.csv.gz\u001B[39m\u001B[38;5;124m'\u001B[39m, compression \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgzip\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava=pd.read_csv('wind_ava.csv.gz', compression = \"gzip\")\n",
    "\n",
    "wind_comp=pd.read_csv('wind_comp.csv.gz', compression = \"gzip\")"
   ],
   "id": "dc4b905db9c02082"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de las primeras muestras de datos de los ficheros iniciales"
   ],
   "id": "d8971cb89e77a588"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.419857500Z"
    }
   },
   "outputs": [],
   "source": [
    "wind_ava.head()"
   ],
   "id": "bec4741988e876b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.428832700Z"
    }
   },
   "outputs": [],
   "source": [
    "wind_ava['datetime'] = pd.to_datetime(wind_ava['datetime'])\n",
    "wind_ava.head()"
   ],
   "id": "7372064d267ed6e6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si modificamos el índice para que este sea la variable *datetime* nos será más simple operar con ello."
   ],
   "id": "aa2bdb4b15d816bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.439801500Z"
    }
   },
   "outputs": [],
   "source": [
    "#wind_ava = wind_ava.set_index('datetime')\n",
    "#wind_ava.head()"
   ],
   "id": "c501b15078dbae96"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Actualmente, el fichero tiene 551 columnas. No las necesitamos todas: sólo usaremos la información sobre la localización de Sotavento, es decir, el número 13 de la cuadrícula de 5x5. \n",
    "\n",
    "A continuación, modificamos el fichero de datos para eliminar las columnas que no necesitamos y quedarnos únicamente con las columnas de variables relativas a la posición 13 de la cuadrícula. Para ello, filtramos las columnas según aquellas que contengan el número 13 en su nombre.\n",
    "Además, nos interesa saber el valor de la energía en cada momento en esa localización, por lo que también filtraremos de forma que no se elimine la variable 'energy'."
   ],
   "id": "3d4cc65d00dc3768"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.451141800Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in wind_ava.columns:\n",
    "    if not c.endswith('.13') and c != 'energy' and c != 'datetime':\n",
    "        wind_ava = wind_ava.drop(c, axis = 1)"
   ],
   "id": "1675079ced1480f3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import time"
   ],
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.460281200Z"
    }
   },
   "id": "dd6eab3afa78cbe9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.465186300Z"
    }
   },
   "outputs": [],
   "source": [
    "wind_ava.head()"
   ],
   "id": "72cc92d7f5fbfcea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, hemos pasado de operar con 551 columnas, a tener sólo 23 columnas en nuestro dataset.\n",
    "En último lugar, es necesario modificar la variable 'datetime' y convertir los datos de la primera columna a formato fecha (pd.to_datetime()) para facilitar su manejo y visualización. Podemos comprobar el resultado de esta modificación en los diagramas de la siguiente sección. "
   ],
   "id": "e4b6fbbbd30f96c1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción general de los datos"
   ],
   "id": "9287a67d39eb6e6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.472516700Z"
    }
   },
   "outputs": [],
   "source": [
    "wind_ava"
   ],
   "id": "74a7f0105804dcb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.478630900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_shape = wind_ava.shape\n",
    "df_shape"
   ],
   "id": "5f3fc14b9c18a625"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro dataset tiene 23 características y 4748 instancias."
   ],
   "id": "54c026b352cc3a51"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:45.490429700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_description \u001B[38;5;241m=\u001B[39m \u001B[43mwind_ava\u001B[49m\u001B[38;5;241m.\u001B[39mdescribe()\n\u001B[0;32m      2\u001B[0m df_description\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "df_description = wind_ava.describe()\n",
    "df_description"
   ],
   "id": "a1257af7b1608ff1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta información resumida sobre los datos disponibles podemos averiguar la media, el mínimo y el máximo y la desviación típica de cada variable, entre otras cosas. \n",
    "\n",
    "En primer lugar, podemos observar que todas nuestras variables son numéricas. \n",
    "\n",
    "También observamos que ningún valor de desviación estándar o desviación típica (std) es igual a 0, por lo que ninguna de las variables de nos interesan (las del sector 13 del mapa) son constantes, y por lo tanto no es necesario modificar el dataset más allá de lo relaizado hasta ahora.\n",
    "\n"
   ],
   "id": "fbe9148f47bbf2b2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado de datos\n",
    "En primer lugar, queremos identificar y eliminar los datos faltantes en nuestro dataset, es decir, aquellos que son *NA*.\n",
    "Para ello identificamos el número de datos faltantes por cada característica."
   ],
   "id": "bd77f8ac726a8cb1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:46.243152200Z",
     "start_time": "2024-03-31T17:53:45.650775500Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mwind_ava\u001B[49m\u001B[38;5;241m.\u001B[39misna()\u001B[38;5;241m.\u001B[39msum()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava.isna().sum()"
   ],
   "id": "9e8b933162daf08b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, no hay ningún valor perdido en nuestros datos, por lo que no necesitamos eliminar ninguna característica. Lo habríamos hecho en el caso de que, para alguna característica, más del 80% de los datos fueran faltantes.\n",
    "\n",
    "A continuación comprobamos que la desviación típica de todas las variables sea diferente de 0, lo que supondría que todas son significativas y aportan valor al modelo. En caso de que este dato tomara valor nulo supondría que esa variable es constante, y posiblemente se valoraría su eliminación del conjunto de datos."
   ],
   "id": "8a839b70d5db1595"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:46.203164300Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mwind_ava\u001B[49m\u001B[38;5;241m.\u001B[39mstd()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava.std()"
   ],
   "id": "f60a175c3bfe6887"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los datos\n",
    "Una vez se ha preprocesado y limpiado el conjunto de los datos, se procede a la creación de diferentes diagramas para recolectar información sobre la distirbución de los datos.\n",
    "Con un diagrama de barras se pueden apreciar las distribuciones de energía recogidas en cada instante de tiempo (representados como el índice del conjunto de datos)."
   ],
   "id": "f210da33c26efa97"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:46.466373400Z",
     "start_time": "2024-03-31T17:53:46.275067700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mwind_ava\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menergy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mplot(rot\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava['energy'].plot(rot=20)"
   ],
   "id": "eac0658e0b50889"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder identificar información sobre los outliers utilizamos un diagrama de caja o boxplot."
   ],
   "id": "c35450560cda26a1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:46.402486200Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mwind_ava\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menergy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mplot\u001B[38;5;241m.\u001B[39mbox()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava['energy'].plot.box()"
   ],
   "id": "a9c1f077ea03c22f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que hay bastantes outliers de energía generada. A pesar de que la mediana se encuentra alrededor de 500, y el tercer cuartil alrededor de 1000, existen bastantes valores fuera del rango intercuartílico, y todos ellos superando el valor de energía generada de 2500, mientras que por debajo del primer cuartil prácticamente no se percibe la existencia de outliers.\n",
    "\n",
    "También se puede observar la frecuencia de energía en los diferentes rangos temporales (calulados con el números de divisiones *bins*) mediante un histograma."
   ],
   "id": "e6a4ab09b3662c99"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:46.586179400Z",
     "start_time": "2024-03-31T17:53:46.500458600Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mwind_ava\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menergy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mplot\u001B[38;5;241m.\u001B[39mhist(bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava['energy'].plot.hist(bins=25)"
   ],
   "id": "4410b746babc9e1a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la distribución se acumula a la izquierda de los valores temporales. Para solucionar un posible sesgo, se puede convertir la variable *energy* a logarítmica de forma que en el gráfico se aprecie como una distribución normal, en lugar de la actual que asemeja una distribución logarítmica.\n",
    "Para realizar esta operación, utilizaremos la librería NumPy. Para ello inicialmente importamos la librería mencionada como se muestra a continuación:"
   ],
   "id": "7e277f8c45aa672a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:46.937666100Z",
     "start_time": "2024-03-31T17:53:46.565236100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "f068d0837a3b2149"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:47.101803700Z",
     "start_time": "2024-03-31T17:53:46.928945700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wind_ava' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m wind_ava[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlog_energy\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlog(\u001B[43mwind_ava\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menergy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      3\u001B[0m wind_ava[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlog_energy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mplot\u001B[38;5;241m.\u001B[39mhist(bins\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'wind_ava' is not defined"
     ]
    }
   ],
   "source": [
    "wind_ava['log_energy'] = np.log(wind_ava['energy'])\n",
    "\n",
    "wind_ava['log_energy'].plot.hist(bins=40)"
   ],
   "id": "82982dfac7a22787"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el resultado no es especialmente relevante, ya que la operación convierte un sesgo a la izquierda en un sesgo a la derecha, de forma que el gráfico resultante no asemeja prácticamente una distirbución normal."
   ],
   "id": "b95bf25f76e17282"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de evaluación Outer & Inner\n",
    "Tras haber estudiado y limpiado el conjunto de datos, se explica la estrategia que se llevará a cabo para evaluar el modelo (*outer*) y para definir el ajuste de hiperparámetros (*inner*).\n",
    "\n",
    "*`Outer`* \n",
    "Para estimar el rendimiento esperado del modelo con datos futuros (para los que no ha sido entrenado), separamos una parte de los datos para evaluar (partición test) el modelo resultante del inner.\n",
    "\n",
    "*`Inner`*\n",
    "Emplearemos Grid Search con Cross Validation y Time Series Splits.\n",
    "\n",
    "Para evlauar el rendimiento de los diferentes modelos se deben escoger una serie de métricas\n",
    "RMSE y MAE y dummy regressor para escalar los datos y en base a ese dummy calcular RSE y RAE.\n",
    "Para hacer el modelo dummy se le quita la media al real\n",
    "ESto nos permite observar el error en términos absoluto y relativo\n",
    "para cross validation MSE y de cara a la evaluación del modelo final tomaríamos todas esta medidas."
   ],
   "id": "e15a86034a57054f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.010474200Z"
    }
   },
   "outputs": [],
   "source": [
    "wind_ava.head()"
   ],
   "id": "1868f995337fd57f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e2346df36a93478e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.020444100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, neighbors, metrics, pipeline, linear_model, svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ],
   "id": "f1551fdd4f10acaf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.027424800Z"
    }
   },
   "outputs": [],
   "source": [
    "#División de conjuntos de evaluación outer. \n",
    "#Dividimos en train y test aprovechando una falta de datos para el año 2009.\n",
    "train= wind_ava[wind_ava['datetime'].dt.year<2009]\n",
    "X_train= train.drop(columns='energy')\n",
    "y_train= train['energy']\n",
    "print(\"train shape is:\", train.shape,\"\\n X_train shape:\",X_train.shape, \"\\n y_train shape: \", y_train.shape)"
   ],
   "id": "9ea7cbad1190cd3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.037935100Z"
    }
   },
   "outputs": [],
   "source": [
    "test= wind_ava[wind_ava['datetime'].dt.year>2008]\n",
    "X_test= test.drop(columns='energy')\n",
    "y_test= test['energy']\n",
    "print(\"test shape is:\", test.shape,\"\\n X_test shape:\",X_test.shape, \"\\n y_train shape: \", y_test.shape)"
   ],
   "id": "dee8f890af346ec4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.044921900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.shape, test.shape, wind_ava.shape)"
   ],
   "id": "e915a346fee8f27c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.051903Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.head()"
   ],
   "id": "b4328b285ebd838d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.059917200Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.set_index('datetime')\n",
    "X_train.head()"
   ],
   "id": "208b853e7c148a4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.063870300Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = X_test.set_index('datetime')"
   ],
   "id": "532c37a253230c54"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de Scaler\n",
    "En esta sección se emplea KNN y CV para encontrar el método de escalado que minimice el error entre las tres opciones que ofrece sklearn: MinMax, Standarization y Robust. \n",
    "Para ello, empleamos un sencillo crossvalidation con un split adecuado para series temporales y medimos el error empleando la métrica escogida (MSE)."
   ],
   "id": "cf9f6e8d7233dc09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.068907300Z"
    }
   },
   "outputs": [],
   "source": [
    "#1) Preparación de datos -usaremos el subset train. \n",
    "scalerCV= TimeSeriesSplit(n_splits=5)\n",
    "scaler_eval= {}"
   ],
   "id": "b47a771b0bd53586"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.071849500Z"
    }
   },
   "outputs": [],
   "source": [
    "#2)Evaluación de scalers\n",
    "#StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipeline_std = sklearn.pipeline.Pipeline([('scaler', StandardScaler()),\n",
    "                                           ('KNN', neighbors.KNeighborsRegressor())])\n",
    "\n",
    "score_std = cross_val_score(pipeline_std, X_train, y_train,cv= scalerCV, scoring='neg_mean_squared_error')\n",
    "\n",
    "scaler_eval[\"StandardScaler\"] = -score_std.mean()"
   ],
   "id": "f36a7df7283e4c6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.074842200Z"
    }
   },
   "outputs": [],
   "source": [
    "#MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "pipeline_mnmx = sklearn.pipeline.Pipeline([('scaler', MinMaxScaler()),\n",
    "                                           ('KNN', neighbors.KNeighborsRegressor())])\n",
    "\n",
    "score_mnmx = cross_val_score(pipeline_mnmx, X_train, y_train,cv= scalerCV, scoring='neg_mean_squared_error')\n",
    "\n",
    "scaler_eval[\"MinMaxScaler\"] = -score_mnmx.mean()"
   ],
   "id": "32a9a395d0247373"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.078919100Z"
    }
   },
   "outputs": [],
   "source": [
    "#RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "pipeline_rbst = sklearn.pipeline.Pipeline([('scaler', RobustScaler()),\n",
    "                                           ('KNN', neighbors.KNeighborsRegressor())])\n",
    "\n",
    "score_rbst = cross_val_score(pipeline_rbst, X_train, y_train,cv= scalerCV, scoring='neg_mean_squared_error')\n",
    "\n",
    "scaler_eval[\"RobustScaler\"] = -score_rbst.mean()"
   ],
   "id": "4d2240b80702d240"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.082820500Z"
    }
   },
   "outputs": [],
   "source": [
    "print(scaler_eval)\n"
   ],
   "id": "cfa6b5c3e2898b4b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando MSE o RMSE, el error más pequeño que hemos obtenido es el de RobustScaler con un valor de 137309."
   ],
   "id": "b3fefe7da2c19e6f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-31T17:53:47.085845Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_mnmx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpipeline_mnmx\u001B[49m\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      2\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m pipeline_mnmx\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m      3\u001B[0m outer_score \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mmean_squared_error(y_test, y_pred)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pipeline_mnmx' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline_mnmx.fit(X_train, y_train)\n",
    "y_pred = pipeline_mnmx.predict(X_test)\n",
    "outer_score = metrics.mean_squared_error(y_test, y_pred)\n",
    "print(outer_score)"
   ],
   "id": "4eaef3da40884dac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Selección de Método\n",
    "En esta sección se miden los tiempos de entrenamiento de diferentes propuestas de modelo para solucionar el problema planeado. \n",
    "A continuación, se realiza una optimización e hiperparámetros (HPO) sobre dichos modelos candidatos y se realizan mediciones temporales del proceso. \n",
    "Finalmente, se emplean los datos recopilados (tiempo y scores de los modelos) para analizar y extraer conclusiones, escogiendo el modelo final que se empleará para solucionar el problema de predicción propuesto. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc31bb68c03904b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) mediciones iniciales\n",
    "Se probarán y evaluarán modelos por defecto de KNN, árboles de regresión, regresión lineal y SMV."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87d0579b5241d420"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TimeSeriesSplit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m time_split\u001B[38;5;241m=\u001B[39m \u001B[43mTimeSeriesSplit\u001B[49m(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      3\u001B[0m times\u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#A. KNN\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#knn train measurement\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'TimeSeriesSplit' is not defined"
     ]
    }
   ],
   "source": [
    "time_split= TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "times= {}\n",
    "#A. KNN\n",
    "\n",
    "#knn train measurement\n",
    "time0= time.time()\n",
    "model= sklearn.pipeline.Pipeline([('scaler',RobustScaler()),\n",
    "                                ('KNN', neighbors.KNeighborsRegressor())])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "time1= time.time()\n",
    "knn_train= time1 - time0\n",
    "\n",
    "#knn cross validation measurement\n",
    "time0= time.time()\n",
    "knn_score= cross_val_score(model, X_train, y_train, cv= time_split, scoring='neg_mean_squared_error')\n",
    "time1= time.time()\n",
    "knn_cv= time1 - time0\n",
    "\n",
    "times[\"KNN\"]= {\"train_time\": knn_train, \"cv_time\":knn_cv, \"total_time\":knn_train + knn_cv, \"score\": -knn_score.mean()}\n",
    "\n",
    "print(\"KNN: \", times[\"KNN\"])\n",
    "\n",
    "#B. Árboles de regresión\n",
    "\n",
    "#tree train measurement\n",
    "time0= time.time()\n",
    "model= sklearn.pipeline.Pipeline([('scaler',RobustScaler()),\n",
    "                                ('RegTree', DecisionTreeRegressor())])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "time1= time.time()\n",
    "tree_train= time1 - time0\n",
    "\n",
    "#tree cross validation measurement\n",
    "time0= time.time()\n",
    "tree_score= cross_val_score(model, X_train, y_train, cv= time_split, scoring='neg_mean_squared_error')\n",
    "time1= time.time()\n",
    "tree_cv= time1 - time0\n",
    "\n",
    "times[\"Tree\"]= {\"train_time\": tree_train, \"cv_time\":tree_cv, \"total_time\":tree_train + tree_cv, \n",
    "                \"score\": -tree_score.mean()}\n",
    "print(\"Tree: \", times[\"Tree\"])\n",
    "\n",
    "#C. Regresor lineal: standard y lasso\n",
    "#C.1. Regular\n",
    "time0= time.time()\n",
    "model= sklearn.pipeline.Pipeline([('scaler',RobustScaler()),\n",
    "                                ('Linear Reg', linear_model.LinearRegression())])\n",
    "model.fit(X_train, y_train)\n",
    "time1= time.time()\n",
    "linear_train= time1 - time0\n",
    "\n",
    "time0= time.time()\n",
    "linear_score= cross_val_score(model, X_train, y_train, cv= time_split, scoring='neg_mean_squared_error')\n",
    "time1= time.time()\n",
    "linear_cv= time1 - time0\n",
    "\n",
    "times[\"Linear\"]= {\"train_time\": linear_train, \"cv_time\":linear_cv, \"total_time\":linear_train + linear_cv, \n",
    "                \"score\": -linear_score.mean()}\n",
    "print(\"Linear Reg: \", times[\"Linear\"])\n",
    "\n",
    "#C.2. Lasso\n",
    "time0= time.time()\n",
    "model= sklearn.pipeline.Pipeline([('scaler',RobustScaler()),\n",
    "                                ('Lasso Reg', linear_model.Lasso())])\n",
    "model.fit(X_train, y_train)\n",
    "time1= time.time()\n",
    "lasso_train= time1 - time0\n",
    "\n",
    "time0= time.time()\n",
    "lasso_score= cross_val_score(model, X_train, y_train, cv= time_split, scoring='neg_mean_squared_error')\n",
    "time1= time.time()\n",
    "lasso_cv= time1 - time0\n",
    "\n",
    "times[\"Lasso\"]= {\"train_time\": lasso_train, \"cv_time\":lasso_cv, \"total_time\":lasso_train + lasso_cv, \n",
    "                \"score\": -lasso_score.mean()}\n",
    "print(\"Lasso Reg: \", times[\"Lasso\"])\n",
    "\n",
    "#D. SMV\n",
    "time0= time.time()\n",
    "model= sklearn.pipeline.Pipeline([('scaler',RobustScaler()),\n",
    "                                ('SMV', svm.SVR())])\n",
    "model.fit(X_train, y_train)\n",
    "time1= time.time()\n",
    "smv_train= time1 - time0\n",
    "\n",
    "time0= time.time()\n",
    "smv_score= cross_val_score(model, X_train, y_train, cv= time_split, scoring='neg_mean_squared_error')\n",
    "time1= time.time()\n",
    "smv_cv= time1 - time0\n",
    "\n",
    "times[\"SMV\"]= {\"train_time\": smv_train, \"cv_time\": smv_cv, \"total_time\":smv_train + smv_cv, \n",
    "                \"score\": -smv_score.mean()}\n",
    "print(\"SMV: \", times[\"SMV\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:50.130664500Z",
     "start_time": "2024-03-31T17:53:47.121718800Z"
    }
   },
   "id": "111286594920affe",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T17:53:50.334220200Z",
     "start_time": "2024-03-31T17:53:50.134651900Z"
    }
   },
   "id": "c4fb56992a1406bb",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
